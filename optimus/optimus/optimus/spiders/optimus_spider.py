"""This program crawls the val-pakproducts site. It grabs the product
information, which can be seen in items.py.

It uses Scrapy and Selenium. We use selenium due to some js loaded data.

We use a Firefox webdriver for the selenium app.

HOW IT WORKS:
This is a Spider that starts at optimusparts.com/shop.
"""

import time
import re
import logging
import itertools
import sys
import signal
import os

from selenium import webdriver, selenium
from selenium.webdriver.support.ui import Select
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException
from scrapy import Selector, signals
from scrapy.spiders import Spider, Rule
from scrapy.linkextractors import LinkExtractor
from scrapy.xlib.pydispatch import dispatcher
from scrapy.spiders import BaseSpider
from scrapy.http import Request, FormRequest
from scrapy.item import Item, Field
from optimus.items import Product, Part
import optimus_variables as opv

class OptimusSpider(Spider):

    # Scrapy variables
    name = 'optimus'
    allowed_domains = ['http://www.optimusparts.com/']
    start_urls = opv.SRS_LINKS


    def __init__(self):
        super(Spider, self).__init__(self)
        self.log = logging.getLogger('optimusLogger')
        self.driver = webdriver.Firefox()

    def __del__(self):
        self.driver.close()
        super(Spider, self).__del__(self)

    def start_requests(self):
        for url in self.start_urls:
            self.log.info("starting...")
            yield Request(
                url=url,
                callback=self.parse_handler,
                dont_filter=True,
            )

    def parse_handler(self, response):
        """Gets the product urls"""
        print(response.url)
        self.driver.get(response.url)
        try:
            WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((
                    By.XPATH,
                    '//table[@id="modelResults"]//tbody'
                ))
            )
        except:
            pass
        for product in self.get_products(response):
            yield product


    def get_products(self, response):
        trs = self.safe_find_elements_by_xpath(
            '//table[@id="modelResults"]//tbody//tr'
        )
        metas = []
        for tr in trs:
            tds = self.safe_find_elements_by_xpath(
                './/td',
                tr
            )
            meta = {}
            for i,td in enumerate(tds):
                if i == 0:
                    meta['modelid'] = self.safe_get_attribute(
                        td, 'textContent'
                    )
                elif i == 1:
                    meta['model'] = self.safe_get_attribute(
                        td, 'textContent'
                    )
                elif i == 2:
                    meta['manufacturer'] = self.safe_get_attribute(
                        td, 'textContent'
                    )
                elif i == 3:
                    meta['category'] = self.safe_get_attribute(
                        td, 'textContent'
                    )
            url = self.safe_get_info(
                './/td/a',
                'href',
                tr
            )
            meta['url'] = url
            metas.append(meta)
        for meta in metas:
            yield self.parse_products(response, meta)


    def parse_products(self, response, meta):
        print(meta['url'])
        wholegood = Product()
        wholegood['parts'] = []
        abbrev = str(response.url)
        wholegood['abbreviation'] = abbrev.rsplit("=", 1)[1]
        for k,v in meta.items():
            wholegood[k] = v
        self.log.info(wholegood['abbreviation'])
        self.driver.get(meta['url'])
        self.driver.implicitly_wait(6)
        # Get wholegood information
        self.scrape_wholegood_info(wholegood)

        products = self.safe_find_elements_by_xpath(
            """
            //div[@id="modelItemContainer"]
            //a[contains(@class, "button-popup")]
            """
        )
        # Part information is generated by javascript.
        # They are populated once you click the link to the part
        # So we click the popup buttons, scrape, and then close them
        for product in products:
            part = Part()
            part['image_urls'] = []
            part['dataid'] = self.safe_get_attribute(product, 'data-id')
            try:
                product.click()
                popup = self.safe_find_element_by_xpath(
                    """
                    //div[contains(@class,
                        "ui-dialog ui-widget ui-widget-content ui-corner-all"
                    )
                    and contains(
                        @style, "display: block"
                    )]
                    """
                )
                if popup:
                    self.scrape_part_info(part, popup)
                    wholegood['parts'].append(part)
                self.close_popup()
            except:
                self.log.info("can't click")
                continue
        for part in wholegood['parts']:
            part['abbreviation'] = wholegood.get('abbreviation')
            part['sku'] = part['abbreviation'] + "_" + part['oem']
        return wholegood


    #-------------------------- HELPERS -------------------------------#
    # scrape_ methods scrape info and add to an Item()
    def scrape_wholegood_info(self, wholegood):
        self.driver.implicitly_wait(3)
        wholegood['image_urls'] = []
        wholegood['imagemap'] = {}
        img_main = self.safe_get_info(
            '//img[@id="imgMain"]', 'src'
        )

        img_whole = self.safe_get_info(
            '//img[@id="imgWhole"]', 'src'
        )
        wholegood['img_main'] = img_main
        wholegood['img_whole'] = img_whole
        wholegood['image_urls'].extend((img_main, img_whole))
        wholegood['title'] = self.safe_get_info(
            '//h2[@id="lblModelName"]', 'textContent'
        )
        # scrape imagemap info
        self._scrape_imagemap_info(wholegood)

    def scrape_part_info(self, part, popup):
        self.driver.implicitly_wait(3)
        # Get description, manufacturer, and part numbers
        self._scrape_tr_tags(popup, part)
        # Get title
        self._scrape_title(popup, part)

        # get image
        self._scrape_img(popup, part)
        #return part

    def _scrape_title(self, root, part):
        part['title'] = self.safe_get_info(
            './/span[@class="ui-dialog-title"]',
            'textContent',
             root
        )

    def _scrape_img(self, root, part):
        img_url = self.safe_get_info('.//img', 'src', root)
        try:
            if not "NoImage" in img_url:
                part['image_urls'].append(img_url)
        except:
            self.log.info("Can't get img {}".format(img_url))
            pass

    def _scrape_tr_tags(self, root, part):
        trs = self.safe_find_elements_by_xpath(
            './/table[@class="detail-pop-table"]//tr',
            root
        )
        try:
            for tr in trs:
                # this gives ALL texts under the tr tag
                # try to add the row text in a Part(), else disregard it
                try:
                    key, info = self.safe_get_attribute(
                        tr, 'textContent'
                    ).split(":")
                    part_key = self.keymapper(key)
                    part[part_key] = info
                except:
                    self.log.info("Can't get text under tr")
                    pass
        except:
            # there were no tr tags.
            self.log.info("No tr tags = {}".format(trs))
            pass
        try:
            opsku = self.safe_get_info(
                './/div[contains(@id, popup-)]//b',
                'textContent',
                root
            ).split(":")[1]
            part['optimus_sku'] = opsku.replace(" ", "")
        except:
            self.log.info("Can't get optimus sku")
            part['optimus_sku'] = part['oem']


    def _scrape_imagemap_info(self, wholegood):
        self.driver.implicitly_wait(3)
        mapname = self.safe_get_info('//map', 'name')
        wholegood['imagemap'][mapname] = {}
        mapareas = self.safe_find_elements_by_xpath(
            '//area'
        )
        for area in mapareas:
            dataid = self.safe_get_attribute(area, 'data-id')
            coords = self.safe_get_attribute(area, 'coords')
            area.click()
            # map imagemap data-ids to part data-ids
            a_tags = self.safe_find_elements_by_xpath(
                """
                //div[contains(@class,
                    "ui-dialog ui-widget ui-widget-content ui-corner-all"
                )
                and contains(
                    @style, "display: block"
                )]
                //a[@class="button-popup modelitemdlg"]
                """
            )
            part_dataids = []
            for a in a_tags:
                part_dataids.append(
                    self.safe_get_attribute(a, 'data-id')
                )
            self.close_popup()
            wholegood['imagemap'][mapname][dataid] = {}
            wholegood_dataid = wholegood['imagemap'][mapname][dataid]
            wholegood_dataid['coords'] = coords
            wholegood_dataid['part_dataids'] = part_dataids

    def get_popup_node(self, elem_num):
        self.driver.implicitly_wait(3)
        return self.driver.find_elements_by_xpath(
            '//div[contains(@id,"popup-")]'
        )[elem_num]

    def get_product_urls(self, products):
        self.driver.implicitly_wait(3)
        urls = []
        for product in products:
            try:
                urls.append(product.get_attribute("href"))
            except:
                self.log.info("product not found.")
                continue
        return urls

    def keymapper(self, key):
        mapper = {
            "Description" : "description",
            "Manufacturer" : "manufacturer",
            "Fits Model" : "fits_model",
            "Manufacturer Item #" : "oem",
        }
        try:
            return mapper[key]
        except:
            self.log.info("No key {}".format(key))
            return None

    def close_popup(self):
        self.driver.implicitly_wait(3)
        exit_button = self.safe_find_element_by_xpath(
            """
            //div[contains(@class,
                "ui-dialog ui-widget ui-widget-content ui-corner-all"
            )
            and contains(
                @style, "display: block"
            )]
            //a[contains(@class,"ui-dialog-titlebar-close")]
            """
        )
        try:
            exit_button.click()
        except:
            pass

    # safe_ methods implement code in a try except block.
    # They return None, if fail
    def safe_scrape_text(self, element):
        self.driver.implicitly_wait(1)
        try:
            return element.text
        except:
            self.log.info(
                "Can't scrape text from {}".format(element)
            )
            return None

    def safe_get_attribute(self, element, attribute):
        self.driver.implicitly_wait(1)
        try:
            return str(element.get_attribute(attribute))
        except:
            self.log.info(
                "Can't get attribute {}".format(attribute)
            )
            return None

    def safe_get_info(self, xpath, attribute, root=None):
        self.driver.implicitly_wait(1)
        try:
            if root:
                return str(
                    root.find_element_by_xpath(xpath).get_attribute(attribute)
                )
            return str(
                self.driver.find_element_by_xpath(
                    xpath
                ).get_attribute(attribute)
            )
        except:
            self.log.info(
                "Can't get attribute with xpath {}".format(attribute)
            )
            return None


    def safe_find_element_by_xpath(self, xpath, node=None):
        self.driver.implicitly_wait(1)
        try:
            if node:
                return node.find_element_by_xpath(xpath)
            else:
                return self.driver.find_element_by_xpath(xpath)
        except:
            self.log.info(
                "Can't get element by xpath {}".format(xpath)
            )
            return None

    def safe_find_elements_by_xpath(self, xpath, node=None):
        self.driver.implicitly_wait(1)
        try:
            if node:
                return node.find_elements_by_xpath(xpath)
            else:
                return self.driver.find_elements_by_xpath(xpath)
        except:
            self.log.info(
                "Can't get elements by xpath {}".format(xpath)
            )
            return None

    def safe_find_element_by_class_name(self, class_name, node=None):
        self.driver.implicitly_wait(1)
        try:
            if node:
                return node.find_element_by_class_name(class_name)
            else:
                return self.driver.find_element_by_class_name(class_name)
        except:
            self.log.info(
                "Can't get element by class {}".format(class_name)
            )
            return None

    def safe_find_element_by_css_selector(self, css_selector, node=None):
        self.driver.implicitly_wait(1)
        try:
            if node:
                return node.find_element_by_css_selector(css_selector)
            else:
                return self.driver.find_element_by_css_selector(css_selector)
        except:
            self.log.info(
                "Can't get element by css_selector {}".format(
                    css_selector
                )
            )
            return None



